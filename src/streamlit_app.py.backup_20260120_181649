import streamlit as st
import asyncio
import os
import sys
# Force UTF-8 for Windows Console
try:
    sys.stdout.reconfigure(encoding='utf-8')
    sys.stderr.reconfigure(encoding='utf-8')
except Exception:
    pass

import nest_asyncio
from dotenv import load_dotenv

# Load Environment Variables
load_dotenv(dotenv_path="config/.env")

# Apply nest_asyncio
nest_asyncio.apply()

# Ensure project root is in path
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.utils import setup_logger
from src.app.ingestion import DocumentIngestion
from src.app.retrieval import RetrievalService
from src.app.generation import GenerationService
from src.app.query_classifier import QueryClassifier
from src.app.history import ChatHistoryManager
from src.core.config import load_config as core_load_config

# Setup Logger
logger = setup_logger('streamlit_logger')

def load_config(config_path="config/settings.yaml"):
    try:
        return core_load_config(config_path)
    except Exception as e:
        st.error(f"Config Error: {e}")
        st.stop()

# Initialize Services Cache
@st.cache_resource
def get_services():
    config = load_config()
    retrieval_service = RetrievalService(config)
    generation_service = GenerationService(config)
    history_manager = ChatHistoryManager() 
    return config, retrieval_service, generation_service, history_manager

async def run_ingestion(config, retrieval_service):
    with st.spinner("üöÄ Analyzing Documents & Processing..."):
        try:
            ingestion = DocumentIngestion(config)
            if ingestion.should_clear_db:
                st.warning("üîÑ Config change detected! Re-building Vector Database...")
                retrieval_service.clear()
            
            chunks = await ingestion.ingest_documents()
            
            if chunks:
                retrieval_service.add_documents(chunks)
                st.success(f"‚ú® Successfully processed {len(chunks)} new chunks!")
            else:
                st.info("No new documents found.")
        except Exception as e:
            st.error(f"Ingestion failed: {e}")

def main():
    st.set_page_config(page_title="Gemini RAG", page_icon="‚ú®", layout="wide")

    # --- CSS FOR GEMINI LOOK (LIGHT MODE) ---
    st.markdown("""
        <style>
        /* Light Theme Fixes */
        .stApp {
            background-color: #FFFFFF;
            color: #1F1F1F;
        }
        /* Sidebar Styling */
        [data-testid="stSidebar"] {
            background-color: #F0F2F6;
            border-right: 1px solid #E0E0E0;
        }
        /* Buttons */
        .stButton button {
            background-color: #F0F2F6;
            color: #1F1F1F;
            border-radius: 20px;
            border: 1px solid #E0E0E0;
            transition: all 0.3s;
        }
        .stButton button:hover {
            background-color: #E0E0E0;
            color: #000;
        }
        /* Chat Input */
        .stChatInputContainer {
             background-color: #FFFFFF;
             border-radius: 25px;
             border: 1px solid #E0E0E0;
             box-shadow: 0px 2px 6px rgba(0,0,0,0.1);
        }
        /* Titles */
        h1, h2, h3 {
            font-family: 'Google Sans', sans-serif;
            color: #1F1F1F;
        }
        </style>
    """, unsafe_allow_html=True)

    # Load Services
    try:
        config, retrieval_service, generation_service, history_manager = get_services()
    except Exception as e:
        st.error(f"Failed to initialize services: {e}")
        st.stop()

    # --- SESSION MANAGEMENT ---
    if "current_session_id" not in st.session_state:
        # Create default session if none exists
        st.session_state.current_session_id = history_manager.create_session()

    # --- SIDEBAR (HISTORY) ---
    with st.sidebar:
        st.title("Gemini RAG")
        
        if st.button("‚ûï New Chat", use_container_width=True):
            st.session_state.current_session_id = history_manager.create_session()
            st.rerun()

        st.divider()
        st.markdown("**Recent**")
        
        # List Sessions
        sessions = history_manager.get_all_sessions()
        for s_id, data in sessions:
            title = data.get("title", "New Chat")
            # Highlight current session
            if s_id == st.session_state.current_session_id:
                title = f"üîµ **{title}**"
            
            if st.button(title, key=s_id, use_container_width=True):
                st.session_state.current_session_id = s_id
                st.rerun()

        st.divider()
        
        # --- ADMIN / DASHBOARD ---
        with st.expander("üõ†Ô∏è Admin & Status"):
            st.markdown("### üìä Ingestion Dashboard")
            
            # Fetch Status directly from DB
            from src.core.database import get_db
            from src.core.models import FileTracking
            
            try:
                db = next(get_db())
                files = db.query(FileTracking).all()
                if files:
                    # Create simple stats
                    total = len(files)
                    completed = sum(1 for f in files if f.status == "COMPLETED")
                    failed = sum(1 for f in files if f.status == "FAILED")
                    
                    st.metric("Total Files", total)
                    col1, col2 = st.columns(2)
                    col1.metric("‚úÖ Done", completed)
                    col2.metric("‚ùå Fail", failed)
                    
                    # Dataframe view
                    data_list = [{"File": f.filename, "Status": f.status} for f in files]
                    st.dataframe(data_list, hide_index=True)
                else:
                    st.info("No ingestion data found.")
                db.close()
            except Exception as e:
                st.error(f"DB Error: {e}")

            if st.button("üîÑ Trigger Re-Ingestion", type="primary"):
                asyncio.run(run_ingestion(config, retrieval_service))
            
            key = os.getenv("GOOGLE_API_KEY", "")
            if key.startswith("AIza"):
                 st.caption(f"üîë Key Active: ...{key[-4:]}")

    # --- MAIN CHAT AREA ---
    current_session = history_manager.get_session(st.session_state.current_session_id)
    if not current_session:
        st.error("Session not found. creating new one.")
        st.session_state.current_session_id = history_manager.create_session()
        st.rerun()

    messages = current_session["messages"]

    # Welcome Screen if Empty
    if not messages:
        st.markdown(
            """
            <div style='text-align: center; margin-top: 50px;'>
                <h1 style='font-size: 3em; background: -webkit-linear-gradient(45deg, #4285F4, #9B72CB, #D96570); -webkit-background-clip: text; -webkit-text-fill-color: transparent;'>
                    Hello, Neel
                </h1>
                <h3 style='color: #666;'>How can I help you analyze your documents today?</h3>
            </div>
            """, 
            unsafe_allow_html=True
        )

    # Render History
    for msg in messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

    from langchain_core.messages import HumanMessage, AIMessage

    # Chat Input
    prompt = st.chat_input("Ask Gemini RAG...")

    if prompt:
        # 1. User Message
        with st.chat_message("user"):
            st.markdown(prompt)
        history_manager.add_message(st.session_state.current_session_id, "user", prompt)

        # 2. Assistant Response
        with st.chat_message("assistant"):
            with st.spinner("Thinking..."):
                try:
                    # Prepare History
                    lc_history = []
                    for msg in current_session["messages"]:
                        if msg["role"] == "user":
                            lc_history.append(HumanMessage(content=msg["content"]))
                        elif msg["role"] == "assistant":
                            lc_history.append(AIMessage(content=msg["content"]))

                    # RAG Pipeline
                    
                    # 1. Expand/Contextualize Query
                    # Note: We now pass history to get_relevant_docs which uses rewrite_query inside.
                    # So explicit expansion here might be redundant or double-work, but 'expand_query' was for German translation?
                    # Let's trust 'get_relevant_docs' with its new 'rewrite_query' (Contextual + Filter) logic.
                    # expanded = generation_service.expand_query(prompt) <-- Removing this to rely on new logic
                    
                    # 2. Retrieve (Pass History!)
                    docs, metrics = retrieval_service.get_relevant_docs(
                        prompt, 
                        top_k=min(15, config['retrieval']['top_k']),  # Use 15 or config value (whichever is higher)
                        chat_history=lc_history
                    )
                    
                    # Continue with RAG pipeline (only for knowledge queries)
                    if not docs:
                        response_text = "I couldn't find relevant info."
                        st.markdown(response_text)
                    else:
                        # [LATENCY DASHBOARD]
                        with st.status("‚è±Ô∏è Performance Analysis", expanded=False):
                            c1, c2, c3 = st.columns(3)
                            c1.metric("üîç Retrieval", f"{metrics['retrieval_seconds']:.2f}s")
                            c2.metric("üîÑ Reranking", f"{metrics['rerank_seconds']:.2f}s")
                            c3.metric("‚ö° Total Search", f"{metrics['total_seconds']:.2f}s")

                        # 3. Streaming Response
                        response_placeholder = st.empty()
                        full_response = ""
                        
                        # Use stream_answer
                        for chunk in generation_service.stream_answer(prompt, docs, chat_history=lc_history):
                            full_response += chunk
                            response_placeholder.markdown(full_response + "‚ñå")
                        
                        response_placeholder.markdown(full_response)
                        response_text = full_response
                    
                    # Save AI Message
                    history_manager.add_message(st.session_state.current_session_id, "assistant", response_text)
                    
                    # Rerun to update title in sidebar if new chat
                    if len(messages) <= 2:
                        st.rerun()
                        
                except Exception as e:
                    st.error(f"Error: {e}")

if __name__ == "__main__":
    main()
