# RAG Production System

Production-ready Retrieval-Augmented Generation (RAG) system with advanced PDF processing, hybrid search, and multilingual support.

## ğŸš€ Features

- **Advanced PDF Processing**: LlamaParse with Gemini 2.5 Flash multimodal parsing
- **Auto-Rotation Fix**: Free PyMuPDF-based rotation detection and correction
- **Hybrid Search**: Dense (text-embedding-004) + Sparse (BM25) retrieval
- **Multilingual Reranking**: Cohere rerank-multilingual-v3.0
- **Parent-Document Retrieval**: Optimized for tables and long-form content
- **Production-Ready**: Celery workers, Redis caching, PostgreSQL tracking

## ğŸ’» System Requirements

### Ubuntu/Debian Setup
Before running the app, you must install Redis Server (critical for the Celery worker queue):
```bash
sudo apt update
sudo apt install redis-server -y
```

### AWS Setup
For EC2 deployments, it is highly recommended to use an IAM Role instead of hardcoded keys:
- **IAM Role**: Attach an IAM Role with `AmazonS3FullAccess` to your EC2 instance.
- This allows the app to authenticate automatically without needing `AWS_ACCESS_KEY_ID` in `.env`.

## ğŸ“‹ Prerequisites

- Docker & Docker Compose
- AWS S3 bucket
- API Keys:
  - Google AI API Key
  - LlamaParse API Key
  - Cohere API Key

## âš¡ Quick Start

### 1. Clone Repository

```bash
git clone https://github.com/Neel28iitm/RAG-.git
cd RAG-
```

### 2. Setup Environment

```bash
# Copy environment template
cp .env.example .env

# Edit with your API keys
nano .env
```

**Required API Keys:**
- `AWS_ACCESS_KEY_ID` & `AWS_SECRET_ACCESS_KEY`
- `GOOGLE_API_KEY`
- `LLAMA_CLOUD_API_KEY`
- `COHERE_API_KEY`
- `QDRANT_URL` & `QDRANT_API_KEY` (for Qdrant Cloud)

### 3. Start All Services

```bash
docker-compose up -d
```

### 4. Access Application

**ğŸŒ Live Demo (Try Now!):**
- **Demo URL**: https://kason-scripless-bok.ngrok-free.dev
- Test the system without setup
- Note: This is a temporary demo instance

---

**Option A: Local Access**
- **Streamlit UI**: http://localhost:8501
- **Qdrant Dashboard**: http://localhost:6333/dashboard

**Option B: Public Access (ngrok)**
```bash
# Install ngrok (if not installed)
# Download from: https://ngrok.com/download

# Expose Streamlit on public URL
ngrok http 8501

# Share the generated URL (e.g., https://abc123.ngrok.io)
```

**Production Deployment:**
- For production, use proper reverse proxy (Nginx)
- Or deploy on cloud platforms (AWS ECS, Google Cloud Run, etc.)
- ngrok is great for testing/demos

## ğŸ“Š Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Streamlit  â”‚  â† User Interface (Port 8501)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Application Layer                â”‚
â”‚  â€¢ Ingestion (PDF Processing)            â”‚
â”‚  â€¢ Retrieval (Hybrid Search + Reranking) â”‚
â”‚  â€¢ Generation (LLM Answers)              â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Celery    â”‚   Redis    â”‚  PostgreSQL  â”‚
â”‚   Worker    â”‚   Cache    â”‚  FileTrackingâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Qdrant    â”‚     AWS S3       â”‚
â”‚  Vectors    â”‚  Document Store  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ Services

| Service | Port | Purpose |
|---------|------|---------|
| Streamlit | 8501 | Web UI |
| Qdrant | 6333 | Vector database |
| PostgreSQL | 5432 | File tracking |
| Redis | 6379 | Cache + Queue |

## ğŸ“ Project Structure

```
src/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ ingestion.py      # PDF processing pipeline
â”‚   â”œâ”€â”€ retrieval.py      # Hybrid search + reranking
â”‚   â”œâ”€â”€ generation.py     # LLM answer generation
â”‚   â””â”€â”€ embedding.py      # Google embeddings
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ config.py         # Configuration loader
â”‚   â”œâ”€â”€ database.py       # PostgreSQL connection
â”‚   â”œâ”€â”€ models.py         # FileTracking model
â”‚   â””â”€â”€ vector_store.py   # Qdrant client
â”œâ”€â”€ worker/
â”‚   â”œâ”€â”€ celery_app.py     # Celery configuration
â”‚   â””â”€â”€ tasks.py          # Background tasks
â””â”€â”€ streamlit_app.py      # Main UI application
```

## ğŸ¯ Usage

### Upload Documents

1. Upload PDFs to S3: `s3://your-bucket/raw/`
2. Navigate to Streamlit UI
3. Click "Trigger Ingestion"
4. Monitor progress in FileTracking

### Query Documents

1. Open Streamlit UI
2. Enter your question
3. Get AI-powered answers with citations

## ğŸ’° Cost Optimization

**Stay within free tier:**
- LlamaParse: 1,000 pages/day FREE
- Process â‰¤10 documents/day (100 pages each)
- **Monthly cost: $0** âœ…

**Paid usage:**
- $0.30 per 100-page document
- $0.0007 per query

## ğŸ” Monitoring & Health Checks

### System Health Dashboard

```bash
# Run comprehensive health check
python scripts/trace_dashboard.py
```

This will verify:
- âœ… Environment variables (API keys)
- âœ… Qdrant connectivity
- âœ… S3 access
- âœ… Database integrity
- âœ… Vector-to-S3 consistency

**Output:** `trace_report.txt` with full system health status

### Quick Status Check

```bash
# Check document processing status
python scripts/check_status.py
```

Shows:
- Total files in database
- Completed/Failed/Processing counts
- Recent errors

### Check Processing Status (Database)

```bash
docker exec rag_postgres psql -U rag_user -d rag_db -c "SELECT filename, status FROM file_tracking;"
```

### View Worker Logs

```bash
docker logs -f rag_celery_worker
```

### Qdrant Collection Stats

```bash
curl http://localhost:6333/collections/rag_production
```

## ğŸ”Œ Backend API Integration

**Note for Developers:** The core backend (`src/app/`) is **completely decoupled** from Streamlit. You can integrate it into any framework.

### FastAPI Integration Example

```python
from fastapi import FastAPI
from src.app.retrieval import RetrievalService
from src.app.generation import GenerationService
from src.core.config import load_config

app = FastAPI()
config = load_config()

retrieval = RetrievalService(config)
generation = GenerationService(config)

@app.post("/chat")
def chat(query: str):
    # Retrieve relevant documents
    docs, metrics = retrieval.get_relevant_docs(query, top_k=10)
    
    # Generate answer
    answer = generation.generate_answer(query, docs)
    
    return {
        "answer": answer,
        "sources": [d.metadata for d in docs],
        "metrics": metrics
    }
```

### Key Services

| Service | File | Purpose |
|---------|------|---------|
| **Ingestion** | `src/app/ingestion.py` | PDF â†’ Chunks |
| **Retrieval** | `src/app/retrieval.py` | Hybrid Search + Reranking |
| **Generation** | `src/app/generation.py` | LLM Answer Generation |
| **Embedding** | `src/app/embedding.py` | Text â†’ Vectors |

All services are **Streamlit-independent** and ready for API wrapping.

## ğŸ› ï¸ Troubleshooting

### Worker Not Processing

```bash
docker restart rag_celery_worker
docker logs -f rag_celery_worker
```

### Database Connection Issues

```bash
docker exec -it rag_postgres psql -U rag_user -d rag_db
```

### Fresh Start (Clear All Data)

```bash
docker-compose down -v
docker-compose up -d
```

## ğŸ”’ Security

- API keys stored in `.env` file (NOT committed to Git)
- PostgreSQL password configurable
- S3 IAM permissions recommended

## ğŸ“ˆ Performance

- **Ingestion**: ~45s per 100-page PDF
- **Retrieval**: <3s (includes reranking)
- **Generation**: Streaming responses

## ğŸŒ Language Support

- Multilingual parsing (English, German, Swedish)
- Multilingual reranking (Cohere)
- Context-aware query rewriting

## ğŸ“ Advanced Features

- **Rotation Auto-Fix**: PyMuPDF-based (FREE)
- **Quality Validation**: Encoding checks
- **Parent-Document Retrieval**: 5000-char parents, 600-char children
- **Metadata Enrichment**: Timestamps, parsing methods, rotation flags
- **Atomic Operations**: Race condition protection
- **S3 Retry Logic**: Network failure handling

## ğŸ“ Development

### Local Setup (Without Docker)

```bash
# Install dependencies
pip install -r requirements.txt

# Start services manually
redis-server &
qdrant --path ./qdrant_storage &

# Start worker
celery -A src.worker.celery_app worker --loglevel=info

# Start Streamlit
streamlit run src/streamlit_app.py
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open Pull Request

## ğŸ“„ License

[Add your license here]

## ğŸ“§ Support

For issues or questions:
- Open a GitHub issue
- Contact: [Your email]

## ğŸ™ Acknowledgments

- LlamaParse for PDF processing
- Google AI for embeddings and generation
- Cohere for multilingual reranking
- Qdrant for vector storage

---

**Built with â¤ï¸ for production deployment**
